{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стъпка 1: Imports и Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample document:\n",
      "ID: install_cloudsync_pro_windows\n",
      "Title: How to Install CloudSync Pro on Windows\n",
      "Product: CloudSync Pro\n",
      "Category: installation\n",
      "Content length: 1094 characters\n"
     ]
    }
   ],
   "source": [
    "with open('data/raw/knowledge_base.json', 'r', encoding='utf-8') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(\"\\nSample document:\")\n",
    "print(f\"ID: {documents[0]['id']}\")\n",
    "print(f\"Title: {documents[0]['title']}\")\n",
    "print(f\"Product: {documents[0]['product']}\")\n",
    "print(f\"Category: {documents[0]['category']}\")\n",
    "print(f\"Content length: {len(documents[0]['content'])} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 1094 characters\n",
      "Number of chunks: 3\n",
      "\n",
      "First chunk (379 chars):\n",
      "# Installing CloudSync Pro on Windows\n",
      "\n",
      "## System Requirements\n",
      "- Windows operating system (latest version recommended)\n",
      "- At least 2GB of free disk space\n",
      "- Internet connection for download and activation\n",
      "\n",
      "## Installation Steps\n",
      "\n",
      "1. **Download the installer**\n",
      "   - Visit our official website at www.example.com\n",
      "   - Navigate to Downloads section\n",
      "   - Select CloudSync Pro for Windows\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def simple_chunk_by_paragraphs(text: str, max_chunk_size: int = 500) -> List[str]:\n",
    "    \"\"\"\n",
    "    Devide text on chunks per paragraphs\n",
    "    \n",
    "    Args:\n",
    "        text: text for chunking\n",
    "        max_chunk_size: max chunk size\n",
    "    \n",
    "    Returns:\n",
    "        List of chunks\n",
    "    \"\"\"\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        para = para.strip()\n",
    "        if not para:\n",
    "            continue\n",
    "            \n",
    "        if len(current_chunk) + len(para) > max_chunk_size and current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = para\n",
    "        else:\n",
    "            current_chunk += \"\\n\\n\" + para if current_chunk else para\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "test_text = documents[0]['content']\n",
    "test_chunks = simple_chunk_by_paragraphs(test_text, max_chunk_size=500)\n",
    "\n",
    "print(f\"Original text: {len(test_text)} characters\")\n",
    "print(f\"Number of chunks: {len(test_chunks)}\")\n",
    "print(f\"\\nFirst chunk ({len(test_chunks[0])} chars):\")\n",
    "print(test_chunks[0])\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 51/51 [00:00<00:00, 54708.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average chunks per document: 1.6\n",
      "\n",
      "Chunk size statistics:\n",
      "  Min: 165 characters\n",
      "  Max: 491 characters\n",
      "  Average: 359 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []        \n",
    "all_metadatas = []       \n",
    "\n",
    "chunk_counter = 0\n",
    "\n",
    "for doc in tqdm(documents, desc=\"Processing documents\"):\n",
    "    chunks = simple_chunk_by_paragraphs(doc['content'], max_chunk_size=500)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = f\"{doc['id']}_chunk_{i}\"\n",
    "        \n",
    "        metadata = {\n",
    "            'chunk_id': chunk_id,\n",
    "            'doc_id': doc['id'],\n",
    "            'title': doc['title'],\n",
    "            'product': doc['product'],\n",
    "            'category': doc['category'],\n",
    "            'chunk_index': i,\n",
    "            'total_chunks': len(chunks),\n",
    "            'text': chunk \n",
    "        }\n",
    "        \n",
    "        all_chunks.append(chunk)\n",
    "        all_metadatas.append(metadata)\n",
    "        chunk_counter += 1\n",
    "\n",
    "print(f\"Average chunks per document: {chunk_counter / len(documents):.1f}\")\n",
    "\n",
    "chunk_lengths = [len(chunk) for chunk in all_chunks]\n",
    "print(f\"\\nChunk size statistics:\")\n",
    "print(f\"  Min: {min(chunk_lengths)} characters\")\n",
    "print(f\"  Max: {max(chunk_lengths)} characters\")\n",
    "print(f\"  Average: {sum(chunk_lengths) / len(chunk_lengths):.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barni\\OneDrive\\Работен плот\\RAG Tech Support\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\barni\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 489.23it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n",
      "Embedding type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "test_embedding = embedding_model.encode(\"Hello world\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "print(f\"Embedding type: {type(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (82, 384)\n",
      "  Dimension: 384\n",
      "  Total vectors: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(\n",
    "    all_chunks,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  Dimension: {embeddings.shape[1]}\")\n",
    "print(f\"  Total vectors: {embeddings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to vector_db/metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "vector_db_dir = \"vector_db\"\n",
    "os.makedirs(vector_db_dir, exist_ok=True)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# IndexFlatL2 = exact search using L2 distance (Euclidean)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, os.path.join(vector_db_dir, 'faiss_index.bin'))\n",
    "\n",
    "with open(os.path.join(vector_db_dir, 'metadata.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_metadatas, f)\n",
    "print(f\"Metadata saved to {vector_db_dir}/metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retrieval with sample queries:\n",
      "\n",
      "================================================================================\n",
      "Result 1:\n",
      "  Product: CloudSync Pro\n",
      "  Title: How to Install CloudSync Pro on Windows\n",
      "  Category: installation\n",
      "  Distance: 0.2742 (lower = better match)\n",
      "  Content preview: # Installing CloudSync Pro on Windows\n",
      "\n",
      "## System Requirements\n",
      "- Windows operating system (latest version recommended)\n",
      "- At least 2GB of free disk spac...\n",
      "\n",
      "Result 2:\n",
      "  Product: CloudSync Pro\n",
      "  Title: How to Install CloudSync Pro on Windows\n",
      "  Category: installation\n",
      "  Distance: 0.2804 (lower = better match)\n",
      "  Content preview: 2. **Run the installer**\n",
      "   - Locate the downloaded file in your Downloads folder\n",
      "   - Double-click to run the installer\n",
      "   - Follow the on-screen ins...\n",
      "\n",
      "Result 3:\n",
      "  Product: CloudSync Pro\n",
      "  Title: How to Install CloudSync Pro on Mac\n",
      "  Category: installation\n",
      "  Distance: 0.2804 (lower = better match)\n",
      "  Content preview: 2. **Run the installer**\n",
      "   - Locate the downloaded file in your Downloads folder\n",
      "   - Double-click to run the installer\n",
      "   - Follow the on-screen ins...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Result 1:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Sync not working\n",
      "  Category: troubleshooting\n",
      "  Distance: 1.1561 (lower = better match)\n",
      "  Content preview: # Sync not working in CloudSync Pro\n",
      "\n",
      "## Problem Description\n",
      "Sync not working\n",
      "\n",
      "## Solution\n",
      "Check your internet connection and ensure the app has necess...\n",
      "\n",
      "Result 2:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Slow sync speed\n",
      "  Category: troubleshooting\n",
      "  Distance: 1.2785 (lower = better match)\n",
      "  Content preview: # Slow sync speed in CloudSync Pro\n",
      "\n",
      "## Problem Description\n",
      "Slow sync speed\n",
      "\n",
      "## Solution\n",
      "Try pausing other uploads/downloads. Check your internet speed...\n",
      "\n",
      "Result 3:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Files not uploading\n",
      "  Category: troubleshooting\n",
      "  Distance: 1.2996 (lower = better match)\n",
      "  Content preview: # Files not uploading in CloudSync Pro\n",
      "\n",
      "## Problem Description\n",
      "Files not uploading\n",
      "\n",
      "## Solution\n",
      "Verify you have sufficient storage space in your accou...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Result 1:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Selective Sync\n",
      "  Category: features\n",
      "  Distance: 1.2928 (lower = better match)\n",
      "  Content preview: # Selective Sync in CloudSync Pro\n",
      "\n",
      "## Overview\n",
      "Choose which folders to sync to your device. This saves disk space by keeping files in the cloud only. ...\n",
      "\n",
      "Result 2:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Sync not working\n",
      "  Category: troubleshooting\n",
      "  Distance: 1.4885 (lower = better match)\n",
      "  Content preview: # Sync not working in CloudSync Pro\n",
      "\n",
      "## Problem Description\n",
      "Sync not working\n",
      "\n",
      "## Solution\n",
      "Check your internet connection and ensure the app has necess...\n",
      "\n",
      "Result 3:\n",
      "  Product: CloudSync Pro\n",
      "  Title: CloudSync Pro: Slow sync speed\n",
      "  Category: troubleshooting\n",
      "  Distance: 1.4902 (lower = better match)\n",
      "  Content preview: # Slow sync speed in CloudSync Pro\n",
      "\n",
      "## Problem Description\n",
      "Slow sync speed\n",
      "\n",
      "## Solution\n",
      "Try pausing other uploads/downloads. Check your internet speed...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Result 1:\n",
      "  Product: TeamChat\n",
      "  Title: TeamChat: Video call quality issues\n",
      "  Category: troubleshooting\n",
      "  Distance: 0.4312 (lower = better match)\n",
      "  Content preview: # Video call quality issues in TeamChat\n",
      "\n",
      "## Problem Description\n",
      "Video call quality issues\n",
      "\n",
      "## Solution\n",
      "Ensure you have a stable internet connection (m...\n",
      "\n",
      "Result 2:\n",
      "  Product: TeamChat\n",
      "  Title: TeamChat: Video Conferencing\n",
      "  Category: features\n",
      "  Distance: 0.4855 (lower = better match)\n",
      "  Content preview: # Video Conferencing in TeamChat\n",
      "\n",
      "## Overview\n",
      "Start instant video calls with up to 50 participants. Screen sharing and recording available on Pro plan...\n",
      "\n",
      "Result 3:\n",
      "  Product: TeamChat\n",
      "  Title: TeamChat: Channels\n",
      "  Category: features\n",
      "  Distance: 0.8775 (lower = better match)\n",
      "  Content preview: # Channels in TeamChat\n",
      "\n",
      "## Overview\n",
      "Organize conversations by topic using channels. Create public channels for team-wide discussions or private channe...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def search_knowledge_base(query: str, n_results: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Search in knowledge base with FAISS\n",
    "    \n",
    "    Args:\n",
    "        query: User's question\n",
    "        n_results: Number of results\n",
    "    \n",
    "    Returns:\n",
    "        Dict with results\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype('float32')\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, n_results)\n",
    "    \n",
    "    results = {\n",
    "        'distances': distances[0].tolist(),\n",
    "        'indices': indices[0].tolist(),\n",
    "        'documents': [],\n",
    "        'metadatas': []\n",
    "    }\n",
    "    \n",
    "    for idx in indices[0]:\n",
    "        metadata = all_metadatas[idx]\n",
    "        results['documents'].append(metadata['text'])\n",
    "        results['metadatas'].append(metadata)\n",
    "    \n",
    "    return results\n",
    "\n",
    "test_queries = [\n",
    "    \"How do I install CloudSync Pro on Windows?\",\n",
    "    \"My files are not syncing\",\n",
    "    \"What is selective sync?\",\n",
    "    \"TeamChat video call problems\"\n",
    "]\n",
    "\n",
    "print(\"Testing retrieval with sample queries:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_knowledge_base(query, n_results=3)\n",
    "    \n",
    "    for i in range(len(results['documents'])):\n",
    "        doc = results['documents'][i]\n",
    "        metadata = results['metadatas'][i]\n",
    "        distance = results['distances'][i]\n",
    "        \n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"  Product: {metadata['product']}\")\n",
    "        print(f\"  Title: {metadata['title']}\")\n",
    "        print(f\"  Category: {metadata['category']}\")\n",
    "        print(f\"  Distance: {distance:.4f} (lower = better match)\")\n",
    "        print(f\"  Content preview: {doc[:150]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    models = ollama.list()\n",
    "    available_models = [m.model for m in models.models]\n",
    "    \n",
    "    if 'llama3.2:3b' in available_models:\n",
    "        MODEL_NAME = 'llama3.2:3b'\n",
    "    elif 'llama3.2:1b' in available_models:\n",
    "        MODEL_NAME = 'llama3.2:1b'\n",
    "    elif available_models:\n",
    "        MODEL_NAME = available_models[0]\n",
    "    else:\n",
    "        raise Exception(\"No models found. Run: ollama pull llama3.2:3b\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Make sure Ollama is running!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline function created!\n"
     ]
    }
   ],
   "source": [
    "def rag_query(question: str, n_results: int = 3, verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Full RAG pipeline: Retrieve + Generate\n",
    "    \n",
    "    Args:\n",
    "        question: User's question\n",
    "        n_results: Number of documents\n",
    "        verbose: show debug info flag\n",
    "    \n",
    "    Returns:\n",
    "        Dict with results\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Searching for: '{question}'\\n\")\n",
    "    \n",
    "    search_results = search_knowledge_base(question, n_results=n_results)\n",
    "    \n",
    "    retrieved_docs = search_results['documents']\n",
    "    retrieved_metadata = search_results['metadatas']\n",
    "    distances = search_results['distances']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Retrieved {len(retrieved_docs)} documents\\n\")\n",
    "        for i, (meta, dist) in enumerate(zip(retrieved_metadata, distances)):\n",
    "            print(f\"  {i+1}. {meta['title']} (distance: {dist:.4f})\")\n",
    "        print()\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join([\n",
    "        f\"Document {i+1} (from {meta['product']} - {meta['category']}):\\n{doc}\"\n",
    "        for i, (doc, meta) in enumerate(zip(retrieved_docs, retrieved_metadata))\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful technical support assistant.\n",
    "\n",
    "Use the following documentation to answer the user's question. \n",
    "If the answer is not in the documentation, say so.\n",
    "Be concise and helpful.\n",
    "\n",
    "Documentation:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Generating answer with LLM...\\n\")\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model=MODEL_NAME,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    \n",
    "    answer = response['response']\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'retrieved_docs': retrieved_docs,\n",
    "        'retrieved_metadata': retrieved_metadata,\n",
    "        'distances': distances,\n",
    "        'context': context\n",
    "    }\n",
    "\n",
    "print(\"RAG pipeline function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAG SYSTEM TEST\n",
      "================================================================================\n",
      "\n",
      "Searching for: 'How do I install CloudSync Pro on Windows?'\n",
      "\n",
      "Retrieved 3 documents\n",
      "\n",
      "  1. How to Install CloudSync Pro on Windows (distance: 0.2742)\n",
      "  2. How to Install CloudSync Pro on Windows (distance: 0.2804)\n",
      "  3. How to Install CloudSync Pro on Mac (distance: 0.2804)\n",
      "\n",
      "Generating answer with LLM...\n",
      "\n",
      "================================================================================\n",
      "FINAL ANSWER:\n",
      "================================================================================\n",
      "To install CloudSync Pro on Windows, follow these steps:\n",
      "\n",
      "1. Go to [this page](https://www.example.com) for the official installation.\n",
      "2. Click \"Download\" to start downloading the installer file.\n",
      "3. Double-click the downloaded installer file to run it.\n",
      "4. Follow the on-screen instructions carefully to complete the installation.\n",
      "\n",
      "Once the installation is done, you can launch CloudSync Pro from your applications menu or sign in with your account credentials to get started.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test query 1\n",
    "question = \"How do I install CloudSync Pro on Windows?\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RAG SYSTEM TEST\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "result = rag_query(question, n_results=3, verbose=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result['answer'])\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
